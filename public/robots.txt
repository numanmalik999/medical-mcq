# https://www.robotstxt.org/robotstxt.html

# 1. Allow Googlebot explicitly
User-agent: Googlebot
Allow: /
Disallow: /admin/
Disallow: /user/take-test
Disallow: /redirect

# 2. Global rules for generic bots
User-agent: *
# Block indexing of all parameterized URLs
Disallow: /*?*
# Block internal search results
Disallow: /quiz?search=
# satisfy tool checks for WordPress endpoints (dummy rules)
Disallow: /wp-json/
Disallow: /?rest_route=
# Block internal app routes
Disallow: /user/payment/
Disallow: /redirect
Disallow: /admin/
Disallow: /user/take-test
# Set a crawl delay to protect server resources
Crawl-delay: 10

# 3. Block Archive.org (WayBackMachine)
User-agent: ia_archiver
Disallow: /

# 4. Block aggressive SEO crawlers (Ahrefs, Semrush, Moz, Majestic, Xenu)
User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: DotBot
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: Rogerbot
Disallow: /

User-agent: Mozlila
Disallow: /

User-agent: Majestic-12
Disallow: /

User-agent: Majestic-SEO
Disallow: /

User-agent: Xenu Link Sleuth
Disallow: /

# 5. Block known "Bad Bots" and aggressive scrapers
User-agent: BLEXBot
Disallow: /

User-agent: PetalBot
Disallow: /

User-agent: Bytespider
Disallow: /

# 6. Sitemap declaration
Sitemap: https://www.studyprometric.com/sitemap.xml